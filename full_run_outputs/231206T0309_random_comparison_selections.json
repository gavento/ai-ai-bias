{
    "item_type": "paper",
    "run_name": "231206T0309",
    "run_permutations": [
        {
            "config": {
                "comparison_engine": "gpt-4-1106-preview",
                "comparison_prompt_key": "better_paper_abstract",
                "description_engine": "gpt-4-1106-preview",
                "description_prompt_key": "write_xml_paper_abstract"
            },
            "description_comparison_selections": [
                {
                    "title": "a_classifierbased_parser_with_li",
                    "human_description": "A Classifier-Based Parser With Linear Run-Time Complexity\n\nWe present a classifier-based parser that produces constituent trees in linear time. The parser uses a basic bottom-up shiftreduce algorithm, but employs a classifier to determine parser actions instead of a grammar. This can be seen as an extension of the deterministic dependency parser of Nivre and Scholz (2004) to full constituent parsing. We show that, with an appropriate feature set used in classification, a very simple one-path greedy parser can perform at the same level of accuracy as more complex parsers. We evaluate our parser on section 23 of the WSJ section of the Penn Treebank, and obtain precision and recall of 87.54% and 87.61%, respectively.",
                    "llm_description": "Abstract:\n\nThis paper presents a classifier-based shift-reduce parser that operates with linear run-time complexity, producing both dependency and constituent structures simultaneously. The parser employs a deterministic approach, guided by a classifier that makes parsing decisions based on the local context, without the need for an explicit grammar. The simplicity and modularity of the parser allow for easy implementation and adaptation with different classifiers and feature sets. Experiments conducted on the Wall Street Journal corpus of the Penn Treebank demonstrate the parser's efficiency and competitive accuracy. The SVM-based version of the parser (SVMpar) achieved over 87% labeled constituent precision and recall with correctly tagged text, and about 86% with automatically assigned POS tags, while maintaining considerable speed advantages over state-of-the-art statistical parsers. The findings highlight the significant impact of classifier choice on parser performance, and future work aims to explore the effects of individual features, additional classification features, different classifiers, and the potential use of a beam strategy to maintain linear run-time while pursuing multiple parses.",
                    "llm_comparison_tally": {
                        "Human": 0,
                        "LLM": 2,
                        "Invalid": 0
                    }
                },
                {
                    "title": "better_hypothesis_testing_for_st",
                    "human_description": "Better Hypothesis Testing for Statistical Machine Translation: Controlling for Optimizer Instability\n\nIn statistical machine translation, a researcher seeks to determine whether some innovation (e.g., a new feature, model, or inference algorithm) improves translation quality in comparison to a baseline system. To answer this question, he runs an experiment to evaluate the behavior of the two systems on held-out data. In this paper, we consider how to make such experiments more statistically reliable. We provide a systematic analysis of the effects of optimizer instability—an extraneous variable that is seldom controlled for—on experimental outcomes, and make recommendations for reporting results more accurately.",
                    "llm_description": "Abstract:\n\nThis paper addresses the challenges in statistical hypothesis testing for machine translation (MT) research, focusing on the effects of optimizer instability on the reliability of experimental results. While previous work has acknowledged the issue of optimizer instability, there has been no systematic study of its impact on hypothesis testing within the field. The authors conducted a series of experiments to demonstrate that optimizer instability can significantly affect the quality of translation, leading to potentially incorrect conclusions if not properly accounted for. The experiments revealed that variations in optimizer parameters and test set selection could introduce substantial noise in the evaluation metrics. The paper proposes a methodology to control such variables by replicating the optimization process with different starting conditions and applying stratified approximate randomization tests. The results indicate that conducting a small number of replications can provide a high degree of confidence in controlling for optimizer instability. Based on these findings, the authors recommend new best practices for significance testing in MT, including performing evaluations multiple times and using the median system according to a trusted metric for manual analysis. The paper concludes that while no experiment can entirely eliminate confounding variables, controlling for optimizer instability is both feasible and essential for producing reliable MT research outcomes.",
                    "llm_comparison_tally": {
                        "Human": 0,
                        "LLM": 2,
                        "Invalid": 0
                    }
                },
                {
                    "title": "fully_unsupervised_discovery_of_",
                    "human_description": "Fully Unsupervised Discovery of Concept-Specific Relationships by Web Mining\n\nWe present a web mining method for discovering and enhancing relationships in which a specified concept (word class) participates. We discover a whole range of relationships focused on the given concept, rather than generic known relationships as in most previous work. Our method is based on clustering patterns that contain concept words and other words related to them. We evaluate the method on three different rich concepts and find that in each case the method generates a broad variety of relationships with good precision.",
                    "llm_description": "Abstract:\n\nThis paper presents a novel method for the fully unsupervised discovery of a variety of natural binary relations involving specific concepts using web mining techniques. The proposed approach starts with a minimal seed set of concept words and iteratively generates a concept class along with relations in which the class participates, without pre-specifying the types of relationships. The method exploits the abundance of information on the web and relies on standard search engine queries, avoiding the need for language-dependent tools or pre-processed corpora.\n\nThe paper outlines the five-step algorithm which includes generalizing the seed, collecting contexts, grouping contexts by target words, identifying similar context groups, and outputting relations. The approach has been evaluated in three domains: countries, fish species, and star constellations. The results indicate high precision and recall in generating concept classes and a diverse set of meaningful binary relations.\n\nThe method is robust, requiring no additional information beyond a corpus and a small set of concept word examples. It shows potential for ontology construction and can greatly benefit research that requires structured information from unstructured text. Future work may extend the method to multiple-word expressions and further explore the relevance of all-to-all relationships for ontology construction.",
                    "llm_comparison_tally": {
                        "Human": 0,
                        "LLM": 2,
                        "Invalid": 0
                    }
                },
                {
                    "title": "efficient_thirdorder_dependency_",
                    "human_description": "Efficient Third-Order Dependency Parsers\n\nWe present algorithms for higher-order dependency parsing that are “third-order” in the sense that they can evaluate substructures containing three dependencies, and “efficient” in the sense that they reonly Importantly, our new parsers can utilize both sibling-style and grandchild-style interactions. We evaluate our parsers on the Penn Treebank and Prague Dependency Treebank, achieving unlabeled attachment scores of 93.04% and 87.38%, respectively.",
                    "llm_description": "**Abstract:**\n\nThis paper introduces new third-order dependency parsing algorithms that enhance the size and variety of the parts used in the factorization of dependency trees, while retaining the computational efficiency of O(n^4) time and O(n^3) space. Dependency grammar has been a valuable syntactic formalism for parsing, but existing algorithms have limitations due to small parts used in the factorization, losing contextual information. Our third-order parsers, Models 1 and 2, incorporate larger parts—grandchild and grand-sibling interactions—into the parsing process to improve performance. We evaluate the parsers on the Penn WSJ Treebank and Prague Dependency Treebank, achieving high unlabeled attachment scores. Our approach leverages the asymmetry of directed trees, where a head can have many modifiers, but a modifier has only one head, to efficiently handle more complex factorizations. The paper also discusses potential extensions of the algorithms and their applications in various NLP tasks. The implementation of the parsers is made freely available to the community.",
                    "llm_comparison_tally": {
                        "Human": 0,
                        "LLM": 2,
                        "Invalid": 0
                    }
                },
                {
                    "title": "pronunciation_modeling_for_impro",
                    "human_description": "Pronunciation Modeling For Improved Spelling Correction\n\nThis paper presents a method for incorporating word pronunciation information in a noisy channel model for spelling correction. The proposed method builds an explicit error model for word pronunciations. By modeling pronunciation similarities between words we achieve a substantial performance improvement over the previous best performing models for spelling correction.",
                    "llm_description": "**Abstract:**\n\nThis paper introduces an innovative approach to spelling correction by incorporating pronunciation modeling to enhance the accuracy of error detection and correction. Traditionally, spelling errors are classified into two types: cognitive, where the writer does not know the correct spelling, and typographic, related to keyboard errors. Current algorithms address these errors by allowing generic string-to-string edits and estimating probabilities for different edit operations. However, these models have limitations, particularly with phonetic errors.\n\nThe authors propose a novel method that explicitly models phonetic errors by building two separate error models using the Brill and Moore learning algorithm—one based on letter sequences and the other on phone-sequence-to-phone-sequence edits. A letter-to-phone model is created to generate pronunciations for misspellings, which is crucial for the phone-sequence model. The authors improved upon existing letter-to-phone conversion models by introducing a series of extensions that resulted in a substantial performance gain.\n\nThe two models are combined using a log-linear model to make spelling correction predictions. The combined model outperforms the letter-based model alone, especially in handling phonetic errors, achieving substantial error reductions. The paper concludes by suggesting future research directions, including the development of a unified model capable of recognizing the nature of spelling errors and exploring the application of the proposed method in various contexts, such as web content, email, and for non-native English speakers.",
                    "llm_comparison_tally": {
                        "Human": 0,
                        "LLM": 2,
                        "Invalid": 0
                    }
                },
                {
                    "title": "a_monolingual_treebased_translat",
                    "human_description": "A Monolingual Tree-based Translation Model for Sentence Simplification\n\nIn this paper, we consider sentence sim plification as a special form of translation with the complex sentence as the source and the simple sentence as the target. We propose a Tree-based Simplification Model (TSM), which, to our knowledge, is the first statistical simplification model covering splitting, dropping, reorderingand substitution integrally. We also de scribe an efficient method to train our model with a large-scale parallel dataset obtained from the Wikipedia and Simple Wikipedia. The evaluation shows that our model achieves better readability scores than a set of baseline systems.",
                    "llm_description": "**Abstract:**\n\nThis paper introduces a novel sentence simplification model called the Tree-based Simplification Model (TSM), which is founded on principles derived from statistical machine translation (SMT). TSM is designed to transform complex sentences into simpler forms by executing a combination of operations such as splitting, dropping, reordering, and phrase/word substitution. The model learns its parameters efficiently from complex-simple parallel datasets, specifically a large-scale dataset compiled from English Wikipedia and Simple English Wikipedia called PWKP.\n\nThe paper presents a detailed description of the different simplification operations, the probabilistic model underlying TSM, and the expectation-maximization (EM) algorithm used for training. A monolingual word mapping technique is also proposed to accelerate the training process significantly. For decoding, TSM incorporates a greedy strategy and integrates language models to generate simplified sentences.\n\nAn extensive evaluation is conducted to compare TSM against four baseline systems, including the state-of-the-art SMT system, Moses. Results indicate that TSM achieves better overall readability scores than the baseline systems, suggesting that it can more effectively simplify sentences. The paper concludes with insights into the strengths of TSM and future directions for enhancing the model.",
                    "llm_comparison_tally": {
                        "Human": 0,
                        "LLM": 2,
                        "Invalid": 0
                    }
                },
                {
                    "title": "joint_unsupervised_coreference_r",
                    "human_description": "Joint Unsupervised Coreference Resolution with Markov Logic\n\nMachine learning approaches to coreference resolution are typically supervised, and require expensive labeled data. Some unsupervised approaches have been proposed (e.g., Haghighi and Klein (2007)), but they are less accurate. In this paper, we present the first unsupervised approach that is competitive with supervised ones. This is made possible by performing joint inference across mentions, in contrast to the pairwise classification typically used in supervised methods, and by using Markov logic as a representation language, which enables us to easily express relations like apposition and predicate nominals. On MUC and ACE datasets, our model outperforms Haghigi and Klein’s one using only a fraction of the training data, and often matches or exceeds the accuracy of state-of-the-art supervised models.",
                    "llm_description": "**Abstract:**\n\nThis paper presents an innovative unsupervised coreference resolution system that uses Markov logic, a combination of probabilistic graphical models and first-order logic, to perform joint inference among text mentions. Coreference resolution, a crucial subtask in natural language processing (NLP), involves identifying noun phrases that refer to the same entity across a document. Current supervised approaches to coreference resolution require labeled training data and are limited by their inability to utilize the vast amounts of unlabeled text available. The proposed system overcomes this limitation by using unsupervised learning, which does not rely on labeled data.\n\nThe authors developed a general-purpose unsupervised learning algorithm for Markov logic and applied it to coreference resolution, testing it on standard MUC and ACE datasets. Their system employs a Markov logic network (MLN) that leverages syntactic relations such as apposition and predicate nominals, which have been previously underutilized due to unsupervised learning challenges.\n\nExperimental results demonstrate that the proposed system outperforms the state-of-the-art unsupervised models and achieves accuracy comparable to supervised models. The system's success is attributed to its use of joint inference and the ability to incorporate relations among mentions. This represents a significant advancement in the field, as it is the first unsupervised system to reach such accuracy levels, holding promise for future enhancements and broader applications in NLP tasks.",
                    "llm_comparison_tally": {
                        "Human": 0,
                        "LLM": 2,
                        "Invalid": 0
                    }
                },
                {
                    "title": "semeval2010_task_13_tempeval2",
                    "human_description": "SemEval-2010 Task 13: TempEval-2\n\nTempeval-2 comprises evaluation tasks for time expressions, events and temporal relations, the latter of which was split up in four sub tasks, motivated by the notion that smaller subtasks would make both data preparation and temporal relation extraction easier. Manually annotated data were",
                    "llm_description": "Abstract:\n\nThe TempEval-2 task, part of the SemEval 2010 competition, aimed to advance the automatic identification of temporal expressions, events, and their relationships within multilingual texts. Building upon its predecessor, TempEval-1, this iteration expanded to include six tasks and increased language coverage to Chinese, English, French, Italian, Korean, and Spanish. The evaluation focused on the extraction of temporal information and the classification of temporal relations using a simplified version of the TimeML annotation language, which employed TIMEX3 for time expressions, EVENT for events, and TLINK for temporal relations. The annotation process, which was supported by the Brandeis Annotation Tool (BAT), involved a dual annotation phase and an adjudication phase to resolve disagreements, ensuring higher accuracy in the temporal annotation. Eight teams participated, submitting eighteen systems with a majority focusing on English and fewer on Spanish, and none on the other four languages. Evaluation metrics included precision, recall, and F1-measure for the extent of events and time expressions, and a straightforward correctness ratio for attributes and relations. The results indicated variability across languages and tasks, with some systems performing better on certain tasks than others, suggesting language-specific challenges in temporal processing. The paper concludes with insights on the complexity of the tasks, the need to optimize the number of tasks for future evaluations, and the logistical challenges encountered. The work contributes to the development of a standard metadata markup language for natural language texts, facilitating the understanding of temporal information within a multilingual context.",
                    "llm_comparison_tally": {
                        "Human": 0,
                        "LLM": 2,
                        "Invalid": 0
                    }
                },
                {
                    "title": "statistical_decisiontree_models_",
                    "human_description": "Statistical Decision-Tree Models For Parsing\n\nSyntactic natural language parsers have shown themselves to be inadequate for processing highly-ambiguous large-vocabulary text, as is evidenced by their poor performance on domains like the Wall Street Journal, and by the movement away from parsing-based approaches to textprocessing in general. In this paper, I describe SPATTER, a statistical parser based on decision-tree learning techniques which constructs a complete parse for every sentence and achieves accuracy rates far better than any published result. This work is based on the following premises: (1) grammars are too complex and detailed to develop manually for most interesting domains; (2) parsing models must rely heavily on lexical and contextual information to analyze sentences accurately; and (3) existing n-grain modeling techniques are inadequate for parsing models. In experiments comparing SPATTER with IBM's computer manuals parser, SPATTER significantly outperforms the grammar-based parser. Evaluating SPATTER against the Penn Treebank Wall Street Journal corpus using the PARSEVAL measures, SPATachieves 86% precision, and 1.3 crossing brackets per sentence for sentences of 40 words or less, and 91% precision, 90% recall, and 0.5 crossing brackets for sentences between 10 and 20 words in length.",
                    "llm_description": "Abstract:\n\nThis paper presents a novel approach to natural language parsing by leveraging statistical decision-tree models to automatically discover disambiguation criteria during the parsing process. Parsing is treated as a sequence of decisions that involve determining parts of speech, choosing constituent structures, and labeling constituents. The SPATTER (Statistical PATTErn Recognizer) parser is introduced, which operates without a complex knowledge base or grammar, using instead statistical data from a large corpus of parsed sentences, combined with information-theoretic classification and training algorithms.\n\nThe SPATTER parser utilizes decision-tree models to non-deterministically pursue all parsing decisions based on estimated probabilities. These models are robust enough to handle a wide array of contextual information crucial for disambiguation in parsing. Furthermore, the paper demonstrates that decision-tree models are equivalent in representational power to interpolated n-gram models but offer advantages in automatic acquisition for large modeling problems.\n\nExperiments comparing SPATTER against a state-of-the-art grammar-based parser in two domains, IBM Computer Manuals and the Wall Street Journal, show that SPATTER outperforms the grammar-based parser in the former and produces competitive results in the latter. The results suggest that statistical models using decision-tree technology can successfully parse natural language without relying on extensive linguistic knowledge, and the parser's performance scales with sentence length. Future work aims to investigate the impact of such a parser on the performance of text processing applications.",
                    "llm_comparison_tally": {
                        "Human": 0,
                        "LLM": 2,
                        "Invalid": 0
                    }
                },
                {
                    "title": "widecoverage_efficient_statistic",
                    "human_description": "Wide-Coverage Efficient Statistical Parsing with CCG and Log-Linear Models\n\nThis article describes a number of log-linear parsing models for an automatically extracted lexicalized grammar. The models are “full” parsing models in the sense that probabilities are defined for complete parses, rather than for independent events derived by decomposing the parse tree. Discriminative training is used to estimate the models, which requires incorrect parses for each sentence in the training data as well as the correct parse. The lexicalized grammar formalism used is Combinatory Categorial Grammar (CCG), and the grammar is automatically extracted from CCGbank, a CCG version of the Penn Treebank. The combination of discriminative training and an automatically extracted grammar leads to a significant memory requirement (up to 25 GB), which is satisfied using a parallel implementation of the BFGS optimization algorithm running on a Beowulf cluster. Dynamic programming over a packed chart, in combination with the parallel implementation, allows us to solve one of the largest-scale estimation problems in the statistical parsing literature in under three hours. A key component of the parsing system, for both training and testing, is a Maximum Entropy supertagger which assigns CCG lexical categories to words in a sentence. The supertagger makes the discriminative training feasible, and also leads to a highly efficient parser. Surprisingly, given CCG’s “spurious ambiguity,” the parsing speeds are significantly higher than those reported for comparable parsers in the literature. We also extend the existing parsing techniques for CCG by developing a new model and efficient parsing algorithm which exploits all derivations, including CCG’s nonstandard derivations. This model and parsing algorithm, when combined with normal-form constraints, give state-of-the-art accuracy for the recovery of predicate–argument dependencies from CCGbank. The parser is also evaluated on DepBank and compared against the RASP parser, outperforming RASP overall and on the majority of relation types. The evaluation on DepBank raises a number of issues regarding parser evaluation. This article provides a comprehensive blueprint for building a wide-coverage CCG parser. We demonstrate that both accurate and highly efficient parsing is possible with CCG.",
                    "llm_description": "Abstract:\n\nThis article presents log-linear models for statistical parsing using Combinatory Categorial Grammar (CCG), demonstrating that accurate and efficient wide-coverage parsing is feasible with CCG. The grammar is automatically extracted from CCGbank, a CCG version of the Penn Treebank, and discriminative training is employed, requiring the use of both correct and incorrect parses during training. A significant memory requirement is addressed using a parallel implementation of the BFGS optimization algorithm. The parsing system incorporates a Maximum Entropy supertagger, which assigns lexical categories to words, making training feasible and enhancing parsing efficiency. Surprisingly, the parsing speeds achieved are higher than those reported for similar parsers. The article also extends existing CCG parsing techniques by developing a new model and parsing algorithm that exploits all possible derivations, including nonstandard derivations. The parser's accuracy in recovering predicate-argument dependencies is state-of-the-art, and evaluations on DepBank show it outperforms the RASP parser. The article provides a comprehensive blueprint for building a wide-coverage CCG parser, a convincing demonstration of the efficiency of CCG parsing, and a detailed discussion of the difficulties associated with cross-formalism parser comparison.",
                    "llm_comparison_tally": {
                        "Human": 0,
                        "LLM": 2,
                        "Invalid": 0
                    }
                }
            ]
        }
    ]
}